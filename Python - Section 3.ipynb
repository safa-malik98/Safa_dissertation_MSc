{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7528de",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "##########################\n",
    "##########################\n",
    "###### SECTION 3 #########\n",
    "##########################\n",
    "##########################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "####################\n",
    "# Data Preparation #\n",
    "####################\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('input.tbl_safa.csv')\n",
    "\n",
    "# Filter positive COVID cases\n",
    "data_filtered = data[(data['cov_det_sarscov2'] == \"POSITIVE\") & \n",
    "                     (data['cov_det_id'].isna()) | (data['cov_det_id'] == \"POSITIVE\")].copy()\n",
    "\n",
    "# Create new column sars_cov2\n",
    "data_filtered.loc[:, 'sars_cov2'] = data_filtered['cov_det_id']\n",
    "\n",
    "# Replace NaN values in sars_cov2 with 'Unknown'\n",
    "data_filtered.loc[:, 'sars_cov2'] = data_filtered['sars_cov2'].fillna('Unknown')\n",
    "\n",
    "# Convert sars_cov2 to a categorical type \n",
    "data_filtered.loc[:, 'sars_cov2'] = pd.Categorical(data_filtered['sars_cov2'],\n",
    "                                                   categories=['POSITIVE', 'Unknown'])\n",
    "\n",
    "\n",
    "# Find complication columns\n",
    "start_col = 'comps_nosocomial_sepsis'\n",
    "end_col = 'comps_empyema'\n",
    "cols_to_update = data_filtered.loc[:, start_col:end_col].columns\n",
    "\n",
    "# Replace NaN values with False for complications\n",
    "data_filtered[cols_to_update] = data_filtered[cols_to_update].fillna(False)\n",
    "\n",
    "\n",
    "# Create the cardiac arrest column based on diagnoses\n",
    "data_filtered['Cardiac arrest'] = data_filtered['comps_cardiac_arrest']\n",
    "\n",
    "# Create the cardiac arrhythmia column based on diagnoses\n",
    "complication_cols = [\n",
    "    'comps_cardiac_arrhythmia',\n",
    "    'comps_ventricular_arrhythmia',\n",
    "    'comps_supraventricular_arrhythmia',\n",
    "    'comps_atrial_fibrillation'\n",
    "]\n",
    "\n",
    "def determine_cardiac_arrhythmia(row):\n",
    "    if row[complication_cols].any():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data_filtered['Cardiac Arrhythmia'] = data_filtered.apply(determine_cardiac_arrhythmia, \n",
    "                                                          axis=1)\n",
    "\n",
    "# Create the stroke column based on diagnoses\n",
    "data_filtered['Stroke'] = data_filtered['comps_stroke']\n",
    "\n",
    "# Create the heart failure column based on diagnoses\n",
    "data_filtered['Heart Failure'] = data_filtered['comps_congestive_heart_failure']\n",
    "\n",
    "\n",
    "# Create the myocardial injury column based on diagnoses\n",
    "myocardial_injury_cols = [\n",
    "    'comps_myocardial_infarction',\n",
    "    'comps_cardiac_ischaemia',\n",
    "    'comps_acute_cardiac_injury',\n",
    "    'comps_cardiogenic_shock',\n",
    "    'comps_st_elevation',\n",
    "    'comps_elevated_troponin'\n",
    "]\n",
    "\n",
    "def determine_myocardial(row):\n",
    "    if row[myocardial_injury_cols].any():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data_filtered['Myocardial Injury'] = data_filtered.apply(determine_myocardial, axis=1)\n",
    "\n",
    "\n",
    "# Create the MACE columnn as composite outcome\n",
    "MACE_cols = ['Cardiac arrest', 'Cardiac Arrhythmia', 'Stroke', \n",
    "             'Heart Failure', 'Myocardial Injury']\n",
    "    \n",
    "def determine_mace_status(row):\n",
    "    if row[MACE_cols].any():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "data_filtered['MACE'] = data_filtered[MACE_cols].apply(determine_mace_status, axis=1)\n",
    "\n",
    "\n",
    "#Drop columns relating to COVID detection\n",
    "columns_to_drop = [\n",
    "    'cov_det_cronavir',\n",
    "    'cov_det_sarscov2',\n",
    "    'cov_id_cronavir',\n",
    "    'cov_id_sarscov2',\n",
    "    'cov_det_id'\n",
    "]\n",
    "\n",
    "data_cleaned = data_filtered.drop(columns=columns_to_drop)\n",
    "\n",
    "\n",
    "# Find column numbers for 'age' and 'lab_wbc'\n",
    "age_col_num = data_cleaned.columns.get_loc('age')\n",
    "lab_wbc_col_num = data_cleaned.columns.get_loc('lab_wbc')\n",
    "date_admit_col_num = data_cleaned.columns.get_loc('date_admit')\n",
    "\n",
    "\n",
    "\n",
    "columns_indices = list(range(3, 67)) + [142]\n",
    "\n",
    "# Calculate percentage of missing values in each row \n",
    "missing_percentage = yo.iloc[:, columns_indices].isnull().mean(axis=1) * 100\n",
    "\n",
    "# Define 50% threshold for rows to keep\n",
    "threshold_50 = 50\n",
    "\n",
    "# Filter rows where missing percentage is less than or equal to 50%\n",
    "rows_to_keep_50 = missing_percentage <= threshold_50\n",
    "data_cleaned_50percent = data_cleaned[rows_to_keep_50]\n",
    "\n",
    "# Count total rows before and after dropping rows with more than 50% missing data\n",
    "rows_after_dropping_50percent = data_cleaned_50percent.shape[0]\n",
    "\n",
    "\n",
    "# Drop rows with missing values in 'slider_sex', 'age', or 'income' columns\n",
    "final_data2 = data_cleaned_50percent.dropna(subset=['slider_sex', 'age', 'income'])\n",
    "\n",
    "final_data2.to_csv('final_data2.csv', index=False)\n",
    "\n",
    "\n",
    "# Count the number of individuals in each country\n",
    "country_counts = final_data2['slider_country'].value_counts()\n",
    "\n",
    "# Identify countries with fewer than 50 individuals\n",
    "countries_to_replace = country_counts[country_counts < 50].index\n",
    "\n",
    "# Replace these country names with 'Other'\n",
    "final_data2['slider_country'] = final_data2['slider_country'].apply(\n",
    "    lambda x: 'Other' if x in countries_to_replace else x)\n",
    "\n",
    "\n",
    "# Add a age group column\n",
    "age_bins = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "age_labels = ['0-10', '10-20', '20-30', '30-40', '40-50', '50-60',\n",
    "              '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "# Categorise ages into the defined bins\n",
    "final_data2['age_group'] = pd.cut(final_data2['age'], bins=age_bins, \n",
    "                                  labels=age_labels, right=False)\n",
    "\n",
    "data = pd.read_csv('final_data2.csv')\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Figure 4 (b-f): Pie chart for age distribution of MACE complications #\n",
    "########################################################################\n",
    "\n",
    "\n",
    "columns_of_interest = [\n",
    "    'Cardiac arrest', 'Cardiac Arrhythmia', 'Stroke', \n",
    "    'Heart Failure', 'Myocardial Injury'\n",
    "]\n",
    "\n",
    "# Combine first five age groups into one '0-50' group\n",
    "combined_age_group = '0-50'\n",
    "age_order = [combined_age_group, '50-60', '60-70', '70-80', '80-90', '90-100']\n",
    "\n",
    "data_copy = data.copy()\n",
    "\n",
    "# Combine age groups in the data\n",
    "data_copy['age_group'] = data_copy['age_group'].replace({\n",
    "    '0-10': combined_age_group,\n",
    "    '10-20': combined_age_group,\n",
    "    '20-30': combined_age_group,\n",
    "    '30-40': combined_age_group,\n",
    "    '40-50': combined_age_group\n",
    "})\n",
    "\n",
    "# Aesthetics for pie charts\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(age_order)))\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(columns_of_interest):\n",
    "    # Filter the data to include only rows where complication present\n",
    "    true_data = data_copy[data_copy[column] == True]\n",
    "    \n",
    "    # Group the filtered data by age category and count the occurrences\n",
    "    age_distribution = true_data['age_group'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    age_distribution = age_distribution.reindex(age_order, fill_value=0)\n",
    "    \n",
    "    # Create pie chart \n",
    "    wedges, texts, autotexts = axes[i].pie(\n",
    "        age_distribution, \n",
    "        labels=age_distribution.index, \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=140, \n",
    "        colors=colors\n",
    "    )\n",
    "    \n",
    "    # Change text appearance\n",
    "    for text in texts:\n",
    "        text.set_color('black')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('black')\n",
    "    \n",
    "    axes[i].set_title(f'Age Distribution for {column}')\n",
    "    axes[i].axis('equal')  \n",
    "\n",
    "    \n",
    "# Show the plot\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Figure 9 (d): Pie chart for age distribution of high income group #\n",
    "########################################################################\n",
    "\n",
    "\n",
    "data_copy2 = data.copy()\n",
    "\n",
    "# Combine age groups in the data\n",
    "combined_age_group = {\n",
    "    '0-10': '0-20',\n",
    "    '10-20': '0-20',\n",
    "    '80-90': '80-100',\n",
    "    '90-100': '80-100'\n",
    "}\n",
    "\n",
    "data_copy2['age_group'] = data_copy2['age_group'].replace(combined_age_group)\n",
    "\n",
    "# Define the order of age groups\n",
    "age_order = ['0-20', '20-30', '30-40', '40-50', '50-60', \n",
    "             '60-70', '70-80', '80-100']\n",
    "\n",
    "# Filter data for high-income group\n",
    "income_data = data_copy2[data_copy2['income'] == 'High income']\n",
    "\n",
    "# Calculate the count of each age group \n",
    "age_group_counts = income_data['age_group'].value_counts().reindex(\n",
    "    age_order, fill_value=0)\n",
    "\n",
    "# Define color palette\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(age_order)))\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(age_group_counts, labels=age_group_counts.index, \n",
    "        autopct=lambda p: f'{p:.1f}%', \n",
    "        startangle=140, counterclock=False, colors=colors, \n",
    "        textprops={'fontsize': 18})\n",
    "plt.axis('equal') \n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################################################\n",
    "# Univariable Logistic Regression - Comorbidities #\n",
    "###################################################\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "start_col = 12\n",
    "end_col = 33\n",
    "\n",
    "# Initialize empty DataFrame\n",
    "comorb_results = pd.DataFrame(columns=['Variable', 'Odds Ratio', '95% CI Lower', \n",
    "                                       '95% CI Upper', 'P-Value'])\n",
    "\n",
    "# Iterate over each column\n",
    "for col in data.columns[start_col:end_col + 1]:\n",
    "    # Prepare the data for logistic regression\n",
    "    try:\n",
    "        X = data[[col]].astype(float)  \n",
    "    except ValueError:\n",
    "        X = pd.get_dummies(data[[col]], drop_first=True)\n",
    "\n",
    "    y = data['MACE'].astype(int)  \n",
    "    \n",
    "    # Drop rows with missing values in both X and y\n",
    "    valid_indices = X.dropna().index.intersection(y.dropna().index)\n",
    "    X = X.loc[valid_indices]\n",
    "    y = y.loc[valid_indices]\n",
    "\n",
    "    # Check for infinite values in X \n",
    "    X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # Add a constant to the independent variable\n",
    "    X = sm.add_constant(X, has_constant='add')\n",
    "    \n",
    "    # Perform logistic regression\n",
    "    model = sm.Logit(y, X)\n",
    "    comorb_result = model.fit(disp=0)  \n",
    "\n",
    "    # Get odds ratio\n",
    "    odds_ratios = np.exp(comorb_result.params)\n",
    "    conf = comorb_result.conf_int()\n",
    "    conf = np.exp(conf)\n",
    "    p_values = comorb_result.pvalues\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    for param in odds_ratios.index:\n",
    "        if param == 'const':\n",
    "            continue  \n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            'Variable': [param],\n",
    "            'Odds Ratio': [odds_ratios[param]],\n",
    "            '95% CI Lower': [conf.loc[param, 0]],\n",
    "            '95% CI Upper': [conf.loc[param, 1]],\n",
    "            'P-Value': [p_values[param]]\n",
    "        })\n",
    "        comorb_results = pd.concat([comorb_results, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "# Save results to a CSV file\n",
    "comorb_results.to_csv('odds_ratio_data.csv', index=False)\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Univariable Logistic Regression - Sex #\n",
    "#########################################\n",
    "\n",
    "\n",
    "# Prepare independent and dependent variables\n",
    "X = pd.get_dummies(data['slider_sex'], drop_first=True).astype(float) \n",
    "y = data['MACE'].astype(int)  \n",
    "\n",
    "# Add constant to the independent variable\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform logistic regression\n",
    "model = sm.Logit(y, X)\n",
    "sex_result = model.fit()\n",
    "\n",
    "# Get the odds ratio, confidence interval, and p-value\n",
    "odds_ratios = np.exp(sex_result.params)\n",
    "conf = sex_result.conf_int()\n",
    "conf = np.exp(conf)\n",
    "p_values = sex_result.pvalues\n",
    "\n",
    "# Create DataFrame\n",
    "sex_results = pd.DataFrame({\n",
    "    'Variable': odds_ratios.index,\n",
    "    'Odds Ratio': odds_ratios.values,\n",
    "    '95% CI Lower': conf.iloc[:, 0].values,\n",
    "    '95% CI Upper': conf.iloc[:, 1].values,\n",
    "    'P-Value': p_values.values\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(sex_results)\n",
    "\n",
    "\n",
    "############################################\n",
    "# Univariable Logistic Regression - Income #\n",
    "############################################\n",
    "\n",
    "# Prepare independent and dependent variables\n",
    "X = pd.get_dummies(data['income'], drop_first=True).astype(float)\n",
    "y = data['MACE'].astype(int)  \n",
    "\n",
    "# Add constant to the independent variable\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform logistic regression\n",
    "model = sm.Logit(y, X)\n",
    "income_result = model.fit()\n",
    "\n",
    "# Get the odds ratio, confidence interval, and p-value\n",
    "odds_ratios = np.exp(income_result.params)\n",
    "conf = income_result.conf_int()\n",
    "conf = np.exp(conf)\n",
    "p_values = income_result.pvalues\n",
    "\n",
    "# Create DataFrame \n",
    "income_results= pd.DataFrame({\n",
    "    'Variable': odds_ratios.index,\n",
    "    'Odds Ratio': odds_ratios.values,\n",
    "    '95% CI Lower': conf.iloc[:, 0].values,\n",
    "    '95% CI Upper': conf.iloc[:, 1].values,\n",
    "    'P-Value': p_values.values\n",
    "})\n",
    "\n",
    "# Display results\n",
    "print(income_results)\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Univariable Logistic Regression - Age #\n",
    "#########################################\n",
    "\n",
    "\n",
    "X = pd.get_dummies(data['age_group'], drop_first=True).astype(float)  \n",
    "y = data['MACE'].astype(int)  \n",
    "\n",
    "# Add constant to independent variable\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Perform logistic regression\n",
    "model = sm.Logit(y, X)\n",
    "age_result = model.fit()\n",
    "\n",
    "# Get the odds ratio, confidence interval, and p-value\n",
    "odds_ratios = np.exp(age_result.params)\n",
    "conf = age_result.conf_int()\n",
    "conf = np.exp(conf)\n",
    "p_values = age_result.pvalues\n",
    "\n",
    "# Create a DataFrame \n",
    "age_results = pd.DataFrame({\n",
    "    'Variable': odds_ratios.index,\n",
    "    'Odds Ratio': odds_ratios.values,\n",
    "    '95% CI Lower': conf.iloc[:, 0].values,\n",
    "    '95% CI Upper': conf.iloc[:, 1].values,\n",
    "    'P-Value': p_values.values\n",
    "})\n",
    "\n",
    "# Display the results\n",
    "print(age_results)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
